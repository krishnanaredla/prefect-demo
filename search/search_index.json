{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Sample Prefect Flow Following is an example for a sample prefect flow Prefect Installation Prefect documentation can be found her prefect for this tutorial we are using prefect local server Installtion $ pip install prefect To use Prefect Server as the backend, run the following command to configure Prefect for local orchestration: $ prefect backend server Please note the server requires Docker and Docker Compose to be running. To start the server, UI, and all required infrastructure, run: $ prefect server start When server is running, navigate to http://localhost:8080 Diabetic Prediction Model First we need to register a project in prefect $ prefect create project sample We need to register our flow $ prefect register -- project \"sample\" -- path diabetic / flows . py we can also use the regsiter.py to register flow $ python ./ register . py Run the flow use the customised pipeline.py for programmatic running of the flow or use prefect cli $ python ./ pipeline . py $ prefect run -- project \"sample\" -- name \"diabetic\" -- watch Use prefect UI to monitor the flow Documentation mkdocs is used in for documentation Note : prefect flows can be visualized locally , for this graphviz needs to be installed and additional prefect dependencies (prefect[viz]) from pip must installed We use github pages to host the documentation of this project $ mkdocs gh-deploy Above will deploy gh pages","title":"Home"},{"location":"#sample-prefect-flow","text":"Following is an example for a sample prefect flow","title":"Sample Prefect Flow"},{"location":"#prefect-installation","text":"Prefect documentation can be found her prefect for this tutorial we are using prefect local server Installtion $ pip install prefect To use Prefect Server as the backend, run the following command to configure Prefect for local orchestration: $ prefect backend server Please note the server requires Docker and Docker Compose to be running. To start the server, UI, and all required infrastructure, run: $ prefect server start When server is running, navigate to http://localhost:8080","title":"Prefect Installation"},{"location":"#diabetic-prediction-model","text":"First we need to register a project in prefect $ prefect create project sample We need to register our flow $ prefect register -- project \"sample\" -- path diabetic / flows . py we can also use the regsiter.py to register flow $ python ./ register . py Run the flow use the customised pipeline.py for programmatic running of the flow or use prefect cli $ python ./ pipeline . py $ prefect run -- project \"sample\" -- name \"diabetic\" -- watch Use prefect UI to monitor the flow","title":"Diabetic Prediction Model"},{"location":"#documentation","text":"mkdocs is used in for documentation Note : prefect flows can be visualized locally , for this graphviz needs to be installed and additional prefect dependencies (prefect[viz]) from pip must installed We use github pages to host the documentation of this project $ mkdocs gh-deploy Above will deploy gh pages","title":"Documentation"},{"location":"dag/","text":"","title":"Dag"},{"location":"flows/","text":"diabetic.flows getFlow Diabetic flow Flow is as follows : -> Extras the data the from locally stored CSV files -> Transforms the data -> Run the data against different models -> LogisticRegression -> KNeighborsClassifier -> RandomForestClassifier -> SVC -> Identify the model with highest score -> Test model with sample data Parameters: Name Type Description Default observations_path str) Observation csv file location required patients_path (str) Patients csv file location required conditions_path (str) Conditions csv file location required output (str) location to store the trained model required testData (list sample data to test model required Exceptions: Type Description AssertionError In testModel task if test failed on sample data Source code in diabetic\\flows.py def getFlow (): \"\"\" Diabetic flow Flow is as follows : -> Extras the data the from locally stored CSV files -> Transforms the data -> Run the data against different models -> LogisticRegression -> KNeighborsClassifier -> RandomForestClassifier -> SVC -> Identify the model with highest score -> Test model with sample data Args: observations_path (str) : Observation csv file location patients_path (str) : Patients csv file location conditions_path (str) : Conditions csv file location output (str) : location to store the trained model testData (list): sample data to test model Raises: AssertionError : In testModel task if test failed on sample data \"\"\" with Flow ( name = \"diabetic\" , storage = Local ()) as diabetic_flow : observations_path = Parameter ( \"observations\" , default = \"./data/observations.csv\" ) patients_path = Parameter ( \"patients\" , default = \"./data/patients.csv\" ) conditions_path = Parameter ( \"conditions\" , default = \"./data/conditions.csv\" ) output = Parameter ( \"output\" ) testData = Parameter ( \"testData\" ) data = load ( observations_path , patients_path , conditions_path ) processed = transform ( data ) lr = RunLogisticRegression ( processed ) knn = RunKNeighborsClassifier ( processed ) rf = RunRandomForestClassifier ( processed ) sv = RunSVC ( processed ) model = identifyandSaveModel ( [ lr , knn , rf , sv ], output , upstream_tasks = [ lr , knn , rf , sv ] ) testModel ( testData , output , upstream_tasks = [ model ]) return diabetic_flow","title":"Flows"},{"location":"flows/#diabetic.flows","text":"","title":"flows"},{"location":"flows/#diabetic.flows.getFlow","text":"Diabetic flow Flow is as follows : -> Extras the data the from locally stored CSV files -> Transforms the data -> Run the data against different models -> LogisticRegression -> KNeighborsClassifier -> RandomForestClassifier -> SVC -> Identify the model with highest score -> Test model with sample data Parameters: Name Type Description Default observations_path str) Observation csv file location required patients_path (str) Patients csv file location required conditions_path (str) Conditions csv file location required output (str) location to store the trained model required testData (list sample data to test model required Exceptions: Type Description AssertionError In testModel task if test failed on sample data Source code in diabetic\\flows.py def getFlow (): \"\"\" Diabetic flow Flow is as follows : -> Extras the data the from locally stored CSV files -> Transforms the data -> Run the data against different models -> LogisticRegression -> KNeighborsClassifier -> RandomForestClassifier -> SVC -> Identify the model with highest score -> Test model with sample data Args: observations_path (str) : Observation csv file location patients_path (str) : Patients csv file location conditions_path (str) : Conditions csv file location output (str) : location to store the trained model testData (list): sample data to test model Raises: AssertionError : In testModel task if test failed on sample data \"\"\" with Flow ( name = \"diabetic\" , storage = Local ()) as diabetic_flow : observations_path = Parameter ( \"observations\" , default = \"./data/observations.csv\" ) patients_path = Parameter ( \"patients\" , default = \"./data/patients.csv\" ) conditions_path = Parameter ( \"conditions\" , default = \"./data/conditions.csv\" ) output = Parameter ( \"output\" ) testData = Parameter ( \"testData\" ) data = load ( observations_path , patients_path , conditions_path ) processed = transform ( data ) lr = RunLogisticRegression ( processed ) knn = RunKNeighborsClassifier ( processed ) rf = RunRandomForestClassifier ( processed ) sv = RunSVC ( processed ) model = identifyandSaveModel ( [ lr , knn , rf , sv ], output , upstream_tasks = [ lr , knn , rf , sv ] ) testModel ( testData , output , upstream_tasks = [ model ]) return diabetic_flow","title":"getFlow()"},{"location":"serving/","text":"serving.streamlit inference Streamlit will be used to serve the model URL : http :// localhost : 8501 Source code in serving\\streamlit.py def inference ( row , model , feat_cols ): \"\"\" Streamlit will be used to serve the model URL: http://localhost:8501 \"\"\" df = pd . DataFrame ([ row ], columns = feat_cols ) print ( float ( model . predict_proba ( df )[ 0 ][ 1 ])) if float ( model . predict_proba ( df )[ 0 ][ 1 ]) < 0.5 : return \"This is a healthy person!\" else : return \"This person has high chances of having diabetics!\"","title":"Serve Model"},{"location":"serving/#serving.streamlit","text":"","title":"streamlit"},{"location":"serving/#serving.streamlit.inference","text":"Streamlit will be used to serve the model URL : http :// localhost : 8501 Source code in serving\\streamlit.py def inference ( row , model , feat_cols ): \"\"\" Streamlit will be used to serve the model URL: http://localhost:8501 \"\"\" df = pd . DataFrame ([ row ], columns = feat_cols ) print ( float ( model . predict_proba ( df )[ 0 ][ 1 ])) if float ( model . predict_proba ( df )[ 0 ][ 1 ]) < 0.5 : return \"This is a healthy person!\" else : return \"This person has high chances of having diabetics!\"","title":"inference()"},{"location":"tasks/","text":"diabetic.tasks RunKNeighborsClassifier Run KNeighborsClassifier Source code in diabetic\\tasks.py @task def RunKNeighborsClassifier ( data : pd . DataFrame ) -> Dict : \"\"\" Run KNeighborsClassifier \"\"\" X_train , X_test , y_train , y_test = splitData ( data ) knn = KNeighborsClassifier () knn . fit ( X_train , y_train ) score = knn . score ( X_test , y_test ) logger = prefect . context . get ( \"logger\" ) logger . info ({ \"model\" : \"KNeighborsClassifier\" , \"score\" : score }) return { \"model\" : \"KNeighborsClassifier\" , \"score\" : score , \"trained\" : knn } RunLogisticRegression Run Logistic Regression Source code in diabetic\\tasks.py @task def RunLogisticRegression ( data : pd . DataFrame ) -> Dict : \"\"\" Run Logistic Regression \"\"\" X_train , X_test , y_train , y_test = splitData ( data ) log_reg = LogisticRegression ( random_state = 0 ) log_reg . fit ( X_train , y_train ) score = log_reg . score ( X_test , y_test ) logger = prefect . context . get ( \"logger\" ) logger . info ({ \"model\" : \"LogisticRegression\" , \"score\" : score }) return { \"model\" : \"LogisticRegression\" , \"score\" : score , \"trained\" : log_reg } RunRandomForestClassifier RUn RandomForestClassifier Source code in diabetic\\tasks.py @task def RunRandomForestClassifier ( data : pd . DataFrame ) -> Dict : \"\"\" RUn RandomForestClassifier \"\"\" clf = RandomForestClassifier () X_train , X_test , y_train , y_test = splitData ( data ) clf . fit ( X_train , y_train ) score = clf . score ( X_test , y_test ) logger = prefect . context . get ( \"logger\" ) logger . info ({ \"model\" : \"RandomForestClassifier\" , \"score\" : score }) return { \"model\" : \"RandomForestClassifier\" , \"score\" : score , \"trained\" : clf } RunSVC Run SVC Source code in diabetic\\tasks.py @task def RunSVC ( data : pd . DataFrame ) -> Dict : \"\"\" Run SVC \"\"\" X_train , X_test , y_train , y_test = splitData ( data ) svm = SVC ( probability = True ) svm . fit ( X_train , y_train ) score = svm . score ( X_test , y_test ) logger = prefect . context . get ( \"logger\" ) logger . info ({ \"model\" : \"SVC\" , \"score\" : score }) return { \"model\" : \"SVC\" , \"score\" : score , \"trained\" : svm } identifyandSaveModel Identify the model with highest score Parameters: Name Type Description Default data List[Dict]) List of scores of all run models required output str) location to store the pickle file required Source code in diabetic\\tasks.py @task def identifyandSaveModel ( data : List [ Dict ], output : str ) -> None : \"\"\" Identify the model with highest score Args: data (List[Dict]) :List of scores of all run models output (str) :location to store the pickle file \"\"\" logger = prefect . context . get ( \"logger\" ) modelFilter = lambda data : max ( data , key = lambda x : x [ \"score\" ]) model = modelFilter ( data ) logger . info ( \"Model with highest score {} \" . format ( model )) pickle . dump ( model [ \"trained\" ], open ( output , \"wb\" )) load Loads the required csv files Parameters: Name Type Description Default observations_path str) Observation csv file location required patients_path (str) Patients csv file location required conditions_path (str) Conditions csv file location required Returns: Type Description Tuple returns tuple of loaded pandas dataframes Source code in diabetic\\tasks.py @task def load ( obPath : str , ptPath : str , cnPath : str ) -> Tuple [ pd . DataFrame , ... ]: \"\"\" Loads the required csv files Args: observations_path (str) : Observation csv file location patients_path (str) : Patients csv file location conditions_path (str) : Conditions csv file location Returns: Tuple: returns tuple of loaded pandas dataframes \"\"\" logger = prefect . context . get ( \"logger\" ) logger . info ( \"Loading the input files\" ) observations = pd . read_csv ( obPath ) patients = pd . read_csv ( ptPath ) conditions = pd . read_csv ( cnPath ) return ( observations , patients , conditions ) splitData Split data into training and test data Args data (pd.DataFrame) : input data Source code in diabetic\\tasks.py def splitData ( data : pd . DataFrame ): \"\"\" Split data into training and test data Args ---------- data (pd.DataFrame) : input data \"\"\" df = data [[ \"systolic\" , \"diastolic\" , \"hdl\" , \"ldl\" , \"bmi\" , \"age\" , \"diabetic\" ]] df . sample ( frac = 1 ) X = df . drop ( \"diabetic\" , axis = 1 ) y = df [ \"diabetic\" ] X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 ) return ( X_train , X_test , y_train , y_test ) testModel test the model data (List[float]) : sample test data output (str) : location of stored pickle file Exceptions: Type Description AssertionError if test failed on sample data Source code in diabetic\\tasks.py @task ( state_handlers = [ handleException ]) def testModel ( data : List [ float ], output ): \"\"\" test the model Args: data (List[float]) : sample test data output (str) : location of stored pickle file Raises: AssertionError: if test failed on sample data \"\"\" logger = prefect . context . get ( \"logger\" ) df = pd . DataFrame ([ pd . Series ( data )]) model = pickle . load ( open ( output , \"rb\" )) prediction = float ( model . predict_proba ( df )[ 0 ][ 1 ]) logger . info ( \"Prediction : {} \" . format ( prediction )) assert prediction > 0.5 logger . info ( \"Model passed for sample data\" ) transform Transforms the data into required training data Parameters: Name Type Description Default dataframes Tuple[pd.DataFrame, ...]) Tuple of input dataframes required Returns: Type Description pd.DataFrame returns training data Source code in diabetic\\tasks.py @task def transform ( dataframes : Tuple [ pd . DataFrame , ... ]) -> pd . DataFrame : \"\"\" Transforms the data into required training data Args: dataframes (Tuple[pd.DataFrame, ...]) : Tuple of input dataframes Returns: pd.DataFrame : returns training data \"\"\" return transformData ( dataframes )","title":"Tasks"},{"location":"tasks/#diabetic.tasks","text":"","title":"tasks"},{"location":"tasks/#diabetic.tasks.RunKNeighborsClassifier","text":"Run KNeighborsClassifier Source code in diabetic\\tasks.py @task def RunKNeighborsClassifier ( data : pd . DataFrame ) -> Dict : \"\"\" Run KNeighborsClassifier \"\"\" X_train , X_test , y_train , y_test = splitData ( data ) knn = KNeighborsClassifier () knn . fit ( X_train , y_train ) score = knn . score ( X_test , y_test ) logger = prefect . context . get ( \"logger\" ) logger . info ({ \"model\" : \"KNeighborsClassifier\" , \"score\" : score }) return { \"model\" : \"KNeighborsClassifier\" , \"score\" : score , \"trained\" : knn }","title":"RunKNeighborsClassifier()"},{"location":"tasks/#diabetic.tasks.RunLogisticRegression","text":"Run Logistic Regression Source code in diabetic\\tasks.py @task def RunLogisticRegression ( data : pd . DataFrame ) -> Dict : \"\"\" Run Logistic Regression \"\"\" X_train , X_test , y_train , y_test = splitData ( data ) log_reg = LogisticRegression ( random_state = 0 ) log_reg . fit ( X_train , y_train ) score = log_reg . score ( X_test , y_test ) logger = prefect . context . get ( \"logger\" ) logger . info ({ \"model\" : \"LogisticRegression\" , \"score\" : score }) return { \"model\" : \"LogisticRegression\" , \"score\" : score , \"trained\" : log_reg }","title":"RunLogisticRegression()"},{"location":"tasks/#diabetic.tasks.RunRandomForestClassifier","text":"RUn RandomForestClassifier Source code in diabetic\\tasks.py @task def RunRandomForestClassifier ( data : pd . DataFrame ) -> Dict : \"\"\" RUn RandomForestClassifier \"\"\" clf = RandomForestClassifier () X_train , X_test , y_train , y_test = splitData ( data ) clf . fit ( X_train , y_train ) score = clf . score ( X_test , y_test ) logger = prefect . context . get ( \"logger\" ) logger . info ({ \"model\" : \"RandomForestClassifier\" , \"score\" : score }) return { \"model\" : \"RandomForestClassifier\" , \"score\" : score , \"trained\" : clf }","title":"RunRandomForestClassifier()"},{"location":"tasks/#diabetic.tasks.RunSVC","text":"Run SVC Source code in diabetic\\tasks.py @task def RunSVC ( data : pd . DataFrame ) -> Dict : \"\"\" Run SVC \"\"\" X_train , X_test , y_train , y_test = splitData ( data ) svm = SVC ( probability = True ) svm . fit ( X_train , y_train ) score = svm . score ( X_test , y_test ) logger = prefect . context . get ( \"logger\" ) logger . info ({ \"model\" : \"SVC\" , \"score\" : score }) return { \"model\" : \"SVC\" , \"score\" : score , \"trained\" : svm }","title":"RunSVC()"},{"location":"tasks/#diabetic.tasks.identifyandSaveModel","text":"Identify the model with highest score Parameters: Name Type Description Default data List[Dict]) List of scores of all run models required output str) location to store the pickle file required Source code in diabetic\\tasks.py @task def identifyandSaveModel ( data : List [ Dict ], output : str ) -> None : \"\"\" Identify the model with highest score Args: data (List[Dict]) :List of scores of all run models output (str) :location to store the pickle file \"\"\" logger = prefect . context . get ( \"logger\" ) modelFilter = lambda data : max ( data , key = lambda x : x [ \"score\" ]) model = modelFilter ( data ) logger . info ( \"Model with highest score {} \" . format ( model )) pickle . dump ( model [ \"trained\" ], open ( output , \"wb\" ))","title":"identifyandSaveModel()"},{"location":"tasks/#diabetic.tasks.load","text":"Loads the required csv files Parameters: Name Type Description Default observations_path str) Observation csv file location required patients_path (str) Patients csv file location required conditions_path (str) Conditions csv file location required Returns: Type Description Tuple returns tuple of loaded pandas dataframes Source code in diabetic\\tasks.py @task def load ( obPath : str , ptPath : str , cnPath : str ) -> Tuple [ pd . DataFrame , ... ]: \"\"\" Loads the required csv files Args: observations_path (str) : Observation csv file location patients_path (str) : Patients csv file location conditions_path (str) : Conditions csv file location Returns: Tuple: returns tuple of loaded pandas dataframes \"\"\" logger = prefect . context . get ( \"logger\" ) logger . info ( \"Loading the input files\" ) observations = pd . read_csv ( obPath ) patients = pd . read_csv ( ptPath ) conditions = pd . read_csv ( cnPath ) return ( observations , patients , conditions )","title":"load()"},{"location":"tasks/#diabetic.tasks.splitData","text":"Split data into training and test data","title":"splitData()"},{"location":"tasks/#diabetic.tasks.splitData--args","text":"data (pd.DataFrame) : input data Source code in diabetic\\tasks.py def splitData ( data : pd . DataFrame ): \"\"\" Split data into training and test data Args ---------- data (pd.DataFrame) : input data \"\"\" df = data [[ \"systolic\" , \"diastolic\" , \"hdl\" , \"ldl\" , \"bmi\" , \"age\" , \"diabetic\" ]] df . sample ( frac = 1 ) X = df . drop ( \"diabetic\" , axis = 1 ) y = df [ \"diabetic\" ] X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 ) return ( X_train , X_test , y_train , y_test )","title":"Args"},{"location":"tasks/#diabetic.tasks.testModel","text":"test the model data (List[float]) : sample test data output (str) : location of stored pickle file Exceptions: Type Description AssertionError if test failed on sample data Source code in diabetic\\tasks.py @task ( state_handlers = [ handleException ]) def testModel ( data : List [ float ], output ): \"\"\" test the model Args: data (List[float]) : sample test data output (str) : location of stored pickle file Raises: AssertionError: if test failed on sample data \"\"\" logger = prefect . context . get ( \"logger\" ) df = pd . DataFrame ([ pd . Series ( data )]) model = pickle . load ( open ( output , \"rb\" )) prediction = float ( model . predict_proba ( df )[ 0 ][ 1 ]) logger . info ( \"Prediction : {} \" . format ( prediction )) assert prediction > 0.5 logger . info ( \"Model passed for sample data\" )","title":"testModel()"},{"location":"tasks/#diabetic.tasks.transform","text":"Transforms the data into required training data Parameters: Name Type Description Default dataframes Tuple[pd.DataFrame, ...]) Tuple of input dataframes required Returns: Type Description pd.DataFrame returns training data Source code in diabetic\\tasks.py @task def transform ( dataframes : Tuple [ pd . DataFrame , ... ]) -> pd . DataFrame : \"\"\" Transforms the data into required training data Args: dataframes (Tuple[pd.DataFrame, ...]) : Tuple of input dataframes Returns: pd.DataFrame : returns training data \"\"\" return transformData ( dataframes )","title":"transform()"}]}